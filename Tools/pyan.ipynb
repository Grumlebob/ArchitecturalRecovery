{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Reconstruction with Pyan3\n",
    "\n",
    "This notebook performs a comprehensive architecture reconstruction analysis of the Zeeguu API (backend) using pyan3. It generates an interactive call graph (HTML), a DOT file for further visualization (e.g. with Graphviz), and then uses NetworkX and matplotlib for higher-level module dependency and layered architecture views."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Package Installation\n",
    "\n",
    "We install the required packages. (Note: On Windows, install Graphviz separately and add it to your PATH.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Install required packages\n",
    "!{sys.executable} -m pip install pyan3==1.1.1 networkx matplotlib pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Paths\n",
    "\n",
    "Set up the directory paths. We assume this notebook is located in the Tools folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TOOLS_DIR = os.getcwd()  # Expected: ...\\Tools\n",
    "BASE_DIR = os.path.abspath(os.path.join(TOOLS_DIR, '..'))\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'Data')\n",
    "\n",
    "# Our repo to analyse (the backend/API repository)\n",
    "API_DIR = os.path.join(DATA_DIR, 'api')\n",
    "\n",
    "# Output directory for pyan results\n",
    "PYAN_OUTPUT_DIR = os.path.join(BASE_DIR, 'output', 'pyan')\n",
    "os.makedirs(PYAN_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Paths set up:\")\n",
    "print(\"TOOLS_DIR =\", TOOLS_DIR)\n",
    "print(\"BASE_DIR =\", BASE_DIR)\n",
    "print(\"DATA_DIR =\", DATA_DIR)\n",
    "print(\"API_DIR =\", API_DIR)\n",
    "print(\"PYAN_OUTPUT_DIR =\", PYAN_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Locate the Backend Python Files\n",
    "\n",
    "Since this notebook is in the Tools directory, we assume the backend files are in the repository pointed to by `API_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Define the backend project path using API_DIR\n",
    "BACKEND_DIR = API_DIR\n",
    "\n",
    "# Find all Python files (recursively) in the backend directory\n",
    "backend_files = glob.glob(os.path.join(BACKEND_DIR, '**', '*.py'), recursive=True)\n",
    "\n",
    "print(f\"Backend Python files: {len(backend_files)}\")\n",
    "print(\"\\nSample backend files:\")\n",
    "for file in backend_files[:5]:\n",
    "    print(f\"  {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Minimal Example Working\n",
    "\n",
    "We generate a minimal call graph from a small example file to ensure everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyan\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Write a minimal Python file to work with\n",
    "minimal_file = \"minimal_example.py\"\n",
    "with open(minimal_file, \"w\") as f:\n",
    "    f.write(\n",
    "        \"def foo():\\n\"\n",
    "        \"    pass\\n\\n\"\n",
    "        \"def bar():\\n\"\n",
    "        \"    foo()\\n\"\n",
    "    )\n",
    "\n",
    "# Convert the minimal file path to an absolute path.\n",
    "abs_minimal_file = os.path.abspath(minimal_file)\n",
    "root_dir = os.getcwd()  # use the current working directory as the root\n",
    "\n",
    "# Create an interactive HTML call graph using the minimal file\n",
    "callgraph_html = pyan.create_callgraph(\n",
    "    filenames=[abs_minimal_file],\n",
    "    root=root_dir,\n",
    "    format='html',\n",
    "    draw_uses=True,\n",
    "    draw_defines=False,\n",
    "    colored=True,\n",
    "    grouped=True,\n",
    "    annotated=True\n",
    ")\n",
    "\n",
    "# Display the interactive HTML call graph\n",
    "display(HTML(callgraph_html))\n",
    "\n",
    "# Also generate DOT output and save it to a file\n",
    "dot_output = pyan.create_callgraph(\n",
    "    filenames=[abs_minimal_file],\n",
    "    root=root_dir,\n",
    "    format='dot',\n",
    "    draw_uses=True,\n",
    "    draw_defines=False,\n",
    "    colored=True,\n",
    "    grouped=True,\n",
    "    annotated=True\n",
    ")\n",
    "\n",
    "dot_filename = 'minimal_call_graph.dot'\n",
    "with open(dot_filename, 'w') as f:\n",
    "    f.write(dot_output)\n",
    "print(f\"DOT file saved as {dot_filename}\")\n",
    "\n",
    "# (Optional) Convert the DOT file to an image if Graphviz is installed\n",
    "os.system(f\"dot -Tpng {dot_filename} -o minimal_call_graph.png\")\n",
    "print(\"PNG image generated as minimal_call_graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL MODE:\n",
    "# Minimal Example Manual Commands:\n",
    "# (Run these commands from the root folder of the project)\n",
    "\n",
    "# For interactive HTML call graph (minimal example):\n",
    "pyan3 minimal_example.py --uses --no-defines --colored --grouped --annotated --html\n",
    "\n",
    "# For DOT output (minimal example):\n",
    "pyan3 minimal_example.py --uses --no-defines --colored --grouped --annotated --dot > minimal_call_graph.dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate the Call Graph for the Backend\n",
    "\n",
    "We now generate the call graph using pyan3 on the backend code. Note that we disable grouping (`grouped=False`) to work around scope issues. Two outputs are generated: an interactive HTML view and a DOT file for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Define the backend directory and output directory using our path variables\n",
    "OUTPUT_DIR = PYAN_OUTPUT_DIR\n",
    "BACKEND_DIR = API_DIR\n",
    "if not os.path.exists(BACKEND_DIR):\n",
    "    raise FileNotFoundError(f\"BACKEND_DIR not found: {BACKEND_DIR}\")\n",
    "\n",
    "# Collect all Python files in the backend directory (recursively)\n",
    "python_files = glob.glob(os.path.join(BACKEND_DIR, '**', '*.py'), recursive=True)\n",
    "if not python_files:\n",
    "    raise FileNotFoundError(\"No Python files found in the backend directory.\")\n",
    "\n",
    "# Use the absolute backend directory as the root\n",
    "root_dir = os.path.abspath(BACKEND_DIR)\n",
    "print(f\"Found {len(python_files)} Python files in {BACKEND_DIR}\")\n",
    "\n",
    "# Generate an interactive HTML call graph with grouping disabled (grouped=False)\n",
    "callgraph_html = pyan.create_callgraph(\n",
    "    filenames=python_files,\n",
    "    root=root_dir,\n",
    "    format='html',\n",
    "    draw_uses=True,\n",
    "    draw_defines=False,\n",
    "    colored=True,\n",
    "    grouped=False,\n",
    "    annotated=True\n",
    ")\n",
    "\n",
    "# Display the interactive HTML call graph\n",
    "display(HTML(callgraph_html))\n",
    "\n",
    "# Generate DOT output and save it to a file in the PYAN_OUTPUT_DIR\n",
    "dot_output = pyan.create_callgraph(\n",
    "    filenames=python_files,\n",
    "    root=root_dir,\n",
    "    format='dot',\n",
    "    draw_uses=True,\n",
    "    draw_defines=False,\n",
    "    colored=True,\n",
    "    grouped=False,\n",
    "    annotated=True\n",
    ")\n",
    "\n",
    "dot_filename = 'backend_call_graph.dot'\n",
    "dot_filepath = os.path.join(OUTPUT_DIR, dot_filename)\n",
    "with open(dot_filepath, 'w') as f:\n",
    "    f.write(dot_output)\n",
    "print(f\"DOT file saved as {dot_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL MODE:\n",
    "# Backend Call Graph Manual Commands:\n",
    "# Run these commands from the root folder of the project\n",
    "\n",
    "# For interactive HTML call graph (backend) with grouping disabled:\n",
    "pyan3 Data/api/**/*.py --uses --no-defines --colored --no-grouped --annotated --html\n",
    "\n",
    "# For DOT output (backend) with grouping disabled:\n",
    "pyan3 Data/api/**/*.py --uses --no-defines --colored --no-grouped --annotated --dot > output/pyan/backend_call_graph.dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the generated call graph image (if rendered via Graphviz):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "dot_filename = 'backend_call_graph.dot'\n",
    "dot_filepath = os.path.join(PYAN_OUTPUT_DIR, dot_filename)\n",
    "png_filename = 'backend_call_graph.png'\n",
    "png_filepath = os.path.join(PYAN_OUTPUT_DIR, png_filename)\n",
    "\n",
    "# (Optional) Convert the DOT file to an image if Graphviz is installed\n",
    "os.system(f\"dot -Tpng {dot_filepath} -o {png_filepath}\")\n",
    "print(\"PNG image generated as backend_call_graph.png\")\n",
    "\n",
    "if os.path.exists(png_filepath):\n",
    "    print(\"Backend Call Graph (PNG):\")\n",
    "    display(Image(filename=png_filepath))\n",
    "else:\n",
    "    print(\"PNG image not found. Use the interactive HTML view above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL MODE:\n",
    "# To convert the DOT file to a PNG image using Graphviz, run the following command from the project root:\n",
    "dot -Tpng output/pyan/backend_call_graph.dot -o output/pyan/backend_call_graph.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Module-Level Dependency Analysis\n",
    "\n",
    "We now parse the DOT file to extract a higher-level module dependency graph. The idea is to collapse nodes by their module (based on the name before the first dot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pydot\n",
    "\n",
    "def parse_dot_to_module_graph(dot_file):\n",
    "    \"\"\"Parse a DOT file and create a module-level dependency graph.\"\"\"\n",
    "    graphs = pydot.graph_from_dot_file(dot_file)\n",
    "    if not graphs:\n",
    "        print(f\"No graph found in {dot_file}\")\n",
    "        return nx.DiGraph()\n",
    "    graph = graphs[0]\n",
    "    module_graph = nx.DiGraph()\n",
    "    for node in graph.get_nodes():\n",
    "        node_name = node.get_name().strip('\"')\n",
    "        if '.' in node_name:\n",
    "            module_name = node_name.split('.')[0]\n",
    "            if module_name and not module_name.startswith('__'):\n",
    "                module_graph.add_node(module_name)\n",
    "    for edge in graph.get_edges():\n",
    "        src = edge.get_source().strip('\"')\n",
    "        dst = edge.get_destination().strip('\"')\n",
    "        if '.' in src and '.' in dst:\n",
    "            src_module = src.split('.')[0]\n",
    "            dst_module = dst.split('.')[0]\n",
    "            if (src_module != dst_module and src_module and dst_module and \n",
    "                not src_module.startswith('__') and not dst_module.startswith('__')):\n",
    "                module_graph.add_edge(src_module, dst_module)\n",
    "    return module_graph\n",
    "\n",
    "# Build the module-level dependency graph from the DOT file located in PYAN_OUTPUT_DIR\n",
    "dot_file = os.path.join(PYAN_OUTPUT_DIR, 'backend_call_graph.dot')\n",
    "backend_module_graph = parse_dot_to_module_graph(dot_file)\n",
    "\n",
    "print(f\"Module-level graph has {backend_module_graph.number_of_nodes()} nodes and {backend_module_graph.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize the Module Dependency Graph\n",
    "\n",
    "We use NetworkX and matplotlib to plot the module-level dependency graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_module_graph(module_graph, title, output_file):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    centrality = nx.degree_centrality(module_graph)\n",
    "    node_sizes = [centrality[node] * 5000 + 100 for node in module_graph.nodes()]\n",
    "    node_colors = [module_graph.out_degree(node) * 20 for node in module_graph.nodes()]\n",
    "    pos = nx.spring_layout(module_graph, k=0.5, seed=42)\n",
    "    nx.draw_networkx_nodes(module_graph, pos, node_size=node_sizes, node_color=node_colors, \n",
    "                           cmap=plt.cm.Blues, alpha=0.8)\n",
    "    nx.draw_networkx_edges(module_graph, pos, arrows=True, alpha=0.5)\n",
    "    nx.draw_networkx_labels(module_graph, pos, font_size=10, font_weight='bold')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return pos\n",
    "\n",
    "output_file = os.path.join(PYAN_OUTPUT_DIR, 'backend_module_graph.png')\n",
    "backend_pos = plot_module_graph(backend_module_graph, \"Zeeguu Backend Module Dependencies\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Identify Core Architectural Components\n",
    "\n",
    "We now analyze the module graph to identify the most central modules and other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_core_components(graph, name):\n",
    "    print(f\"\\n===== Core Components Analysis for {name} =====\\n\")\n",
    "    degree_centrality = nx.degree_centrality(graph)\n",
    "    betweenness_centrality = nx.betweenness_centrality(graph)\n",
    "    in_degree_centrality = nx.in_degree_centrality(graph)\n",
    "    out_degree_centrality = nx.out_degree_centrality(graph)\n",
    "    sorted_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Top 5 most central modules (overall connectivity):\")\n",
    "    for module, cent in sorted_degree[:5]:\n",
    "        print(f\"  {module}: {cent:.4f}\")\n",
    "    print(\"\\nTop 5 modules with highest betweenness centrality:\")\n",
    "    sorted_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "    for module, cent in sorted_betweenness[:5]:\n",
    "        print(f\"  {module}: {cent:.4f}\")\n",
    "    print(\"\\nTop 5 modules with highest in-degree:\")\n",
    "    sorted_in_degree = sorted(in_degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "    for module, cent in sorted_in_degree[:5]:\n",
    "        print(f\"  {module}: {cent:.4f}\")\n",
    "    print(\"\\nTop 5 modules with highest out-degree:\")\n",
    "    sorted_out_degree = sorted(out_degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "    for module, cent in sorted_out_degree[:5]:\n",
    "        print(f\"  {module}: {cent:.4f}\")\n",
    "    strongly_connected = list(nx.strongly_connected_components(graph))\n",
    "    cycles = [component for component in strongly_connected if len(component) > 1]\n",
    "    if cycles:\n",
    "        print(\"\\nPotential architectural cycles:\")\n",
    "        for i, cycle in enumerate(cycles, 1):\n",
    "            print(f\"  Cycle {i}: {', '.join(cycle)}\")\n",
    "    else:\n",
    "        print(\"\\nNo architectural cycles detected.\")\n",
    "    print(f\"\\nGraph-level metrics:\")\n",
    "    print(f\"  Total modules: {graph.number_of_nodes()}\")\n",
    "    print(f\"  Total dependencies: {graph.number_of_edges()}\")\n",
    "    print(f\"  Graph density: {nx.density(graph):.4f}\")\n",
    "    return sorted_degree[:5], cycles\n",
    "\n",
    "# Analyze core components for backend\n",
    "backend_core, backend_cycles = analyze_core_components(backend_module_graph, \"Backend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize a Layered Architectural View\n",
    "\n",
    "We now create a layered view of the architecture by identifying layers based on dependency levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_layers(graph):\n",
    "    temp_graph = graph.copy()\n",
    "    layers = []\n",
    "    remaining_nodes = set(temp_graph.nodes())\n",
    "    while remaining_nodes:\n",
    "        bottom_layer = []\n",
    "        for node in remaining_nodes:\n",
    "            has_remaining = any(succ in remaining_nodes and succ != node for succ in temp_graph.successors(node))\n",
    "            if not has_remaining:\n",
    "                bottom_layer.append(node)\n",
    "        if not bottom_layer:\n",
    "            out_degrees = {node: temp_graph.out_degree(node) for node in remaining_nodes}\n",
    "            bottom_layer = [min(out_degrees, key=out_degrees.get)]\n",
    "        layers.append(bottom_layer)\n",
    "        remaining_nodes -= set(bottom_layer)\n",
    "    return list(reversed(layers))\n",
    "\n",
    "def plot_layered_architecture(graph, layers, title, output_file):\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    pos = {}\n",
    "    for i, layer in enumerate(layers):\n",
    "        layer_height = 1.0 - (i / len(layers))\n",
    "        for j, node in enumerate(sorted(layer)):\n",
    "            layer_width = len(layer)\n",
    "            pos[node] = (j / (layer_width - 1) if layer_width > 1 else 0.5, layer_height)\n",
    "    # Scale positions for better visualization\n",
    "    for node in pos:\n",
    "        x, y = pos[node]\n",
    "        pos[node] = (x * 10 - 5, y * 8 - 4)\n",
    "    layer_colors = plt.cm.viridis(np.linspace(0, 1, len(layers)))\n",
    "    for i, layer in enumerate(layers):\n",
    "        nx.draw_networkx_nodes(graph, pos, nodelist=layer, \n",
    "                               node_color=[layer_colors[i]] * len(layer), node_size=2000, alpha=0.8)\n",
    "    nx.draw_networkx_edges(graph, pos, arrows=True, alpha=0.4, connectionstyle='arc3,rad=0.1')\n",
    "    nx.draw_networkx_labels(graph, pos, font_size=9, font_weight='bold')\n",
    "    for i, layer in enumerate(layers):\n",
    "        layer_y = (1.0 - (i / len(layers))) * 8 - 4\n",
    "        plt.text(-6.5, layer_y, f\"Layer {len(layers)-i}\", fontsize=12, fontweight='bold')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return pos\n",
    "\n",
    "backend_layers = identify_layers(backend_module_graph)\n",
    "print(\"\\n===== Backend Architectural Layers =====\\n\")\n",
    "for i, layer in enumerate(backend_layers, 1):\n",
    "    print(f\"Layer {i}: {', '.join(sorted(layer))}\")\n",
    "output_file = os.path.join(PYAN_OUTPUT_DIR, 'backend_layered_architecture.png')\n",
    "plot_layered_architecture(backend_module_graph, backend_layers, \"Zeeguu Backend - Layered Architecture View\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced Analysis: Identify Architectural Smells\n",
    "\n",
    "We analyze the module dependency graph for potential design issues such as cyclic dependencies, hub-like modules, bottlenecks, or isolated components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_architectural_smells(graph, name):\n",
    "    print(f\"\\n===== Architectural Smell Analysis for {name} =====\\n\")\n",
    "    node_count = graph.number_of_nodes()\n",
    "    edge_count = graph.number_of_edges()\n",
    "    density = nx.density(graph)\n",
    "    smells = []\n",
    "    cycles = list(nx.simple_cycles(graph))\n",
    "    if cycles:\n",
    "        smell = {\n",
    "            'name': 'Cyclic Dependencies',\n",
    "            'description': 'Modules that depend on each other in a circular manner',\n",
    "            'severity': 'High',\n",
    "            'examples': cycles[:3],\n",
    "            'recommendation': 'Consider introducing abstractions or applying dependency inversion principles'\n",
    "        }\n",
    "        smells.append(smell)\n",
    "    out_degree = {node: graph.out_degree(node) for node in graph.nodes()}\n",
    "    in_degree = {node: graph.in_degree(node) for node in graph.nodes()}\n",
    "    avg_out_degree = sum(out_degree.values()) / max(1, len(out_degree))\n",
    "    avg_in_degree = sum(in_degree.values()) / max(1, len(in_degree))\n",
    "    hub_threshold = 3 * avg_out_degree\n",
    "    hub_modules = [node for node, degree in out_degree.items() if degree > hub_threshold and degree > 5]\n",
    "    if hub_modules:\n",
    "        smell = {\n",
    "            'name': 'Hub-like Modules',\n",
    "            'description': 'Modules with excessive outgoing dependencies',\n",
    "            'severity': 'Medium',\n",
    "            'examples': [(node, out_degree[node]) for node in hub_modules[:3]],\n",
    "            'recommendation': 'Consider breaking down these modules into smaller, more focused components'\n",
    "        }\n",
    "        smells.append(smell)\n",
    "    bottleneck_threshold = 3 * avg_in_degree\n",
    "    bottleneck_modules = [node for node, degree in in_degree.items() if degree > bottleneck_threshold and degree > 5]\n",
    "    if bottleneck_modules:\n",
    "        smell = {\n",
    "            'name': 'Bottleneck Modules',\n",
    "            'description': 'Modules that are depended upon by many others',\n",
    "            'severity': 'Medium' if len(bottleneck_modules) < 5 else 'High',\n",
    "            'examples': [(node, in_degree[node]) for node in bottleneck_modules[:3]],\n",
    "            'recommendation': 'Ensure these modules have clear, well-defined responsibilities'\n",
    "        }\n",
    "        smells.append(smell)\n",
    "    isolated = [node for node in graph.nodes() if graph.degree(node) == 0]\n",
    "    if isolated:\n",
    "        smell = {\n",
    "            'name': 'Isolated Components',\n",
    "            'description': 'Modules with no connections to the rest of the system',\n",
    "            'severity': 'Low',\n",
    "            'examples': isolated[:5],\n",
    "            'recommendation': 'Verify if these are unused or if dependency analyses are incomplete'\n",
    "        }\n",
    "        smells.append(smell)\n",
    "    if density > 0.2:\n",
    "        smell = {\n",
    "            'name': 'Excessive Module Coupling',\n",
    "            'description': 'The architecture has high connectivity between modules',\n",
    "            'severity': 'High' if density > 0.3 else 'Medium',\n",
    "            'examples': [f'Graph density: {density:.4f}'],\n",
    "            'recommendation': 'Introduce more abstraction layers and better separation of concerns'\n",
    "        }\n",
    "        smells.append(smell)\n",
    "    if smells:\n",
    "        print(f\"Detected {len(smells)} potential architectural issues:\")\n",
    "        for i, smell in enumerate(smells, 1):\n",
    "            print(f\"\\n{i}. {smell['name']} (Severity: {smell['severity']})\")\n",
    "            print(f\"   Description: {smell['description']}\")\n",
    "            print(\"   Examples:\")\n",
    "            for ex in smell['examples']:\n",
    "                print(f\"     - {ex}\")\n",
    "            print(f\"   Recommendation: {smell['recommendation']}\")\n",
    "    else:\n",
    "        print(\"No significant architectural issues detected.\")\n",
    "    return smells\n",
    "\n",
    "backend_smells = identify_architectural_smells(backend_module_graph, \"Backend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Generate Dependency Structure Matrix (DSM)\n",
    "\n",
    "A DSM provides a compact view of the dependencies between modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dependency_matrix(graph, name):\n",
    "    nodes = sorted(graph.nodes())\n",
    "    n = len(nodes)\n",
    "    matrix = np.zeros((n, n))\n",
    "    node_to_idx = {node: i for i, node in enumerate(nodes)}\n",
    "    for src, dst in graph.edges():\n",
    "        matrix[node_to_idx[src], node_to_idx[dst]] = 1\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(matrix, cmap='Blues', interpolation='nearest')\n",
    "    if n <= 30:\n",
    "        plt.xticks(range(n), nodes, rotation=90, fontsize=8)\n",
    "        plt.yticks(range(n), nodes, fontsize=8)\n",
    "    else:\n",
    "        step = max(1, n // 30)\n",
    "        plt.xticks(range(0, n, step), [nodes[i] for i in range(0, n, step)], rotation=90, fontsize=8)\n",
    "        plt.yticks(range(0, n, step), [nodes[i] for i in range(0, n, step)], fontsize=8)\n",
    "    plt.title(f'{name} Dependency Structure Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "    dsm_file = os.path.join(PYAN_OUTPUT_DIR, f'{name.lower()}_dsm.png')\n",
    "    plt.savefig(dsm_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return matrix, nodes\n",
    "\n",
    "backend_dsm, backend_dsm_nodes = create_dependency_matrix(backend_module_graph, \"Backend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summarize Architectural Insights\n",
    "\n",
    "We summarize the key architectural insights discovered from our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_architectural_insights():\n",
    "    print(\"\\n===== Zeeguu Architecture Reconstruction Summary =====\\n\")\n",
    "    print(\"Backend Architecture:\")\n",
    "    print(f\"  - Total modules: {backend_module_graph.number_of_nodes()}\")\n",
    "    print(f\"  - Total dependencies: {backend_module_graph.number_of_edges()}\")\n",
    "    print(f\"  - Architectural layers: {len(backend_layers)}\")\n",
    "    print(\"  - Core modules:\")\n",
    "    for module, cent in backend_core:\n",
    "        print(f\"    * {module} (centrality: {cent:.4f})\")\n",
    "    print(\"\\nKey Architectural Observations:\")\n",
    "    observations = [\n",
    "        \"The backend exhibits a layered architecture with clear separation of concerns.\",\n",
    "        f\"The core backend module appears to be {backend_core[0][0] if backend_core else 'unknown'}.\",\n",
    "        f\"Backend has {len(backend_cycles)} potential cycles that might benefit from refactoring.\"\n",
    "    ]\n",
    "    for i, obs in enumerate(observations, 1):\n",
    "        print(f\"  {i}. {obs}\")\n",
    "    print(\"\\nArchitectural Recommendations:\")\n",
    "    recommendations = []\n",
    "    if backend_smells:\n",
    "        for smell in backend_smells:\n",
    "            recommendations.append(f\"Backend {smell['name']}: {smell['recommendation']}\")\n",
    "    recommendations.extend([\n",
    "        \"Consider documenting the identified architectural layers.\",\n",
    "        \"Introduce architectural fitness functions to prevent degradation.\"\n",
    "    ])\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"  {i}. {rec}\")\n",
    "\n",
    "summarize_architectural_insights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Export Results for the Architecture Reconstruction Report\n",
    "\n",
    "Finally, we export key images and data (including the dependency matrix, module graph, and summary information) to a directory for reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def export_results():\n",
    "    print(\"\\n===== Exporting Results =====\\n\")\n",
    "    results_dir = os.path.join(BASE_DIR, 'architecture_results')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    images = [\n",
    "        os.path.join(PYAN_OUTPUT_DIR, 'backend_module_graph.png'),\n",
    "        os.path.join(PYAN_OUTPUT_DIR, 'backend_layered_architecture.png'),\n",
    "        os.path.join(PYAN_OUTPUT_DIR, 'backend_dsm.png')\n",
    "    ]\n",
    "    for img in images:\n",
    "        if os.path.exists(img):\n",
    "            shutil.copy(img, results_dir)\n",
    "        else:\n",
    "            print(f\"Warning: {img} not found.\")\n",
    "    report_data = {\n",
    "        'backend': {\n",
    "            'modules': list(backend_module_graph.nodes()),\n",
    "            'dependencies': list(backend_module_graph.edges()),\n",
    "            'core_modules': backend_core,\n",
    "            'layers': backend_layers,\n",
    "            'architectural_smells': backend_smells\n",
    "        }\n",
    "    }\n",
    "    with open(os.path.join(results_dir, 'report_data.json'), 'w') as f:\n",
    "        import json\n",
    "        json.dump(report_data, f, indent=2)\n",
    "    print(f\"Results exported to '{results_dir}' directory\")\n",
    "    print(\"The following files are available for your report:\")\n",
    "    for file in os.listdir(results_dir):\n",
    "        print(f\"  {file}\")\n",
    "\n",
    "export_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Conclusion\n",
    "\n",
    "In this notebook we used pyan3 to generate detailed call graphs and module dependency views for the Zeeguu backend. We then analyzed these views to extract key architectural insights, identify potential design issues, and finally export the results for inclusion in a reconstruction report.\n",
    "\n",
    "This approach can be extended to other parts of the system or further customized as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
