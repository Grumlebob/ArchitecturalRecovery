{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Reconstruction with Pyan\n",
    "\n",
    "This notebook implements a comprehensive architecture reconstruction analysis of the Zeeguu system using Pyan. We'll analyze both the API (backend) and frontend components to generate useful architectural views."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Basic Analysis\n",
    "\n",
    "First, let's install Pyan and ensure we have all necessary dependencies. (Note: On Windows, please install Graphviz separately if needed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (Graphviz must be installed on Windows manually)\n",
    "import sys\n",
    "!{sys.executable} -m pip install pyan networkx matplotlib pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what Python files we have in the backend and frontend directories to understand the scale of our analysis. Since this notebook is located in `Root/Tools`, we reference the project files in `../Data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Define project paths relative to the notebook location\n",
    "BACKEND_DIR = os.path.join('..', 'Data', 'api')\n",
    "FRONTEND_DIR = os.path.join('..', 'Data', 'frontend')\n",
    "\n",
    "# Count Python files in backend and frontend\n",
    "backend_files = glob.glob(os.path.join(BACKEND_DIR, '**', '*.py'), recursive=True)\n",
    "frontend_files = glob.glob(os.path.join(FRONTEND_DIR, '**', '*.py'), recursive=True)\n",
    "\n",
    "print(f\"Backend Python files: {len(backend_files)}\")\n",
    "print(f\"Frontend Python files: {len(frontend_files)}\")\n",
    "print(f\"Total Python files: {len(backend_files) + len(frontend_files)}\")\n",
    "\n",
    "# Display a sample of file paths\n",
    "print(\"\\nSample backend files:\")\n",
    "for file in backend_files[:5]:\n",
    "    print(f\"  {file}\")\n",
    "\n",
    "print(\"\\nSample frontend files:\")\n",
    "for file in frontend_files[:5]:\n",
    "    print(f\"  {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Basic Call Graphs\n",
    "\n",
    "Let's generate separate call graphs for the backend and frontend. This avoids overwhelming complexity in a single graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a call graph for backend Python files\n",
    "!pyan \"{BACKEND_DIR}/**/*.py\" --dot --colored --grouped --annotated --no-defines --no-redundant --output backend_call_graph.dot\n",
    "\n",
    "# Generate a call graph for frontend Python files\n",
    "!pyan \"{FRONTEND_DIR}/**/*.py\" --dot --colored --grouped --annotated --no-defines --no-redundant --output frontend_call_graph.dot\n",
    "\n",
    "# Convert the DOT files to PNG images using Graphviz\n",
    "!dot -Tpng backend_call_graph.dot -o backend_call_graph.png\n",
    "!dot -Tpng frontend_call_graph.dot -o frontend_call_graph.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the generated call graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"Backend Call Graph:\")\n",
    "display(Image(filename='backend_call_graph.png'))\n",
    "\n",
    "print(\"\\nFrontend Call Graph:\")\n",
    "display(Image(filename='frontend_call_graph.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Enhanced Analysis: Module-Level Dependency View\n",
    "\n",
    "Now, let's create a higher-level module view by filtering the call graph to show only relationships between modules rather than individual functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def parse_dot_to_module_graph(dot_file):\n",
    "    \"\"\"Parse a DOT file and create a module-level dependency graph.\"\"\"\n",
    "    # Read the DOT file\n",
    "    graphs = pydot.graph_from_dot_file(dot_file)\n",
    "    if not graphs:\n",
    "        print(f\"No graph found in {dot_file}\")\n",
    "        return nx.DiGraph()\n",
    "    graph = graphs[0]\n",
    "    \n",
    "    # Create a directed graph for module dependencies\n",
    "    module_graph = nx.DiGraph()\n",
    "    \n",
    "    # Extract module names from nodes\n",
    "    for node in graph.get_nodes():\n",
    "        node_name = node.get_name().strip('\"')\n",
    "        if '.' in node_name:\n",
    "            module_name = node_name.split('.')[0]\n",
    "            if module_name and not module_name.startswith('__'):\n",
    "                module_graph.add_node(module_name)\n",
    "    \n",
    "    # Extract module dependencies from edges\n",
    "    for edge in graph.get_edges():\n",
    "        src = edge.get_source().strip('\"')\n",
    "        dst = edge.get_destination().strip('\"')\n",
    "        \n",
    "        if '.' in src and '.' in dst:\n",
    "            src_module = src.split('.')[0]\n",
    "            dst_module = dst.split('.')[0]\n",
    "            if (src_module != dst_module and src_module and dst_module and \n",
    "                not src_module.startswith('__') and not dst_module.startswith('__')):\n",
    "                module_graph.add_edge(src_module, dst_module)\n",
    "    \n",
    "    return module_graph\n",
    "\n",
    "def plot_module_graph(module_graph, title, output_file):\n",
    "    \"\"\"Plot the module dependency graph and save to file.\"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Calculate node sizes based on degree centrality\n",
    "    centrality = nx.degree_centrality(module_graph)\n",
    "    node_sizes = [centrality[node] * 5000 + 100 for node in module_graph.nodes()]\n",
    "    \n",
    "    # Set node colors based on out-degree\n",
    "    node_colors = [module_graph.out_degree(node) * 20 for node in module_graph.nodes()]\n",
    "    \n",
    "    pos = nx.spring_layout(module_graph, k=0.5, seed=42)\n",
    "    nx.draw_networkx_nodes(module_graph, pos, node_size=node_sizes, node_color=node_colors, \n",
    "                           cmap=plt.cm.Blues, alpha=0.8)\n",
    "    nx.draw_networkx_edges(module_graph, pos, arrows=True, alpha=0.5)\n",
    "    nx.draw_networkx_labels(module_graph, pos, font_size=10, font_weight='bold')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return pos\n",
    "\n",
    "# Process backend module dependencies\n",
    "backend_module_graph = parse_dot_to_module_graph('backend_call_graph.dot')\n",
    "backend_pos = plot_module_graph(backend_module_graph, 'Zeeguu Backend Module Dependencies', 'backend_module_graph.png')\n",
    "\n",
    "# Process frontend module dependencies\n",
    "frontend_module_graph = parse_dot_to_module_graph('frontend_call_graph.dot')\n",
    "frontend_pos = plot_module_graph(frontend_module_graph, 'Zeeguu Frontend Module Dependencies', 'frontend_module_graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identify Core Architectural Components\n",
    "\n",
    "Let's analyze the module graphs to identify the core components in the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_core_components(graph, name):\n",
    "    \"\"\"Identify and analyze core components in the architecture.\"\"\"\n",
    "    print(f\"\\n===== Core Components Analysis for {name} =====\\n\")\n",
    "    \n",
    "    # Calculate centrality measures\n",
    "    degree_centrality = nx.degree_centrality(graph)\n",
    "    betweenness_centrality = nx.betweenness_centrality(graph)\n",
    "    in_degree_centrality = nx.in_degree_centrality(graph)\n",
    "    out_degree_centrality = nx.out_degree_centrality(graph)\n",
    "    \n",
    "    sorted_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"Top 5 most central modules (overall connectivity):\")\n",
    "    for module, cent in sorted_degree[:5]:\n",
    "        print(f\"  {module}: {cent:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop 5 modules with highest betweenness centrality:\")\n",
    "    sorted_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "    for module, cent in sorted_betweenness[:5]:\n",
    "        print(f\"  {module}: {cent:.4f}\")\n",
    "        \n",
    "    print(\"\\nTop 5 modules with highest in-degree:\")\n",
    "    sorted_in_degree = sorted(in_degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "    for module, cent in sorted_in_degree[:5]:\n",
    "        print(f\"  {module}: {cent:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop 5 modules with highest out-degree:\")\n",
    "    sorted_out_degree = sorted(out_degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "    for module, cent in sorted_out_degree[:5]:\n",
    "        print(f\"  {module}: {cent:.4f}\")\n",
    "    \n",
    "    # Identify potential cycles\n",
    "    strongly_connected = list(nx.strongly_connected_components(graph))\n",
    "    cycles = [component for component in strongly_connected if len(component) > 1]\n",
    "    if cycles:\n",
    "        print(\"\\nPotential architectural cycles:\")\n",
    "        for i, cycle in enumerate(cycles, 1):\n",
    "            print(f\"  Cycle {i}: {', '.join(cycle)}\")\n",
    "    else:\n",
    "        print(\"\\nNo architectural cycles detected.\")\n",
    "    \n",
    "    print(f\"\\nGraph-level metrics:\")\n",
    "    print(f\"  Total modules: {graph.number_of_nodes()}\")\n",
    "    print(f\"  Total dependencies: {graph.number_of_edges()}\")\n",
    "    print(f\"  Graph density: {nx.density(graph):.4f}\")\n",
    "    \n",
    "    return sorted_degree[:5], cycles\n",
    "\n",
    "# Analyze core components for backend and frontend\n",
    "backend_core, backend_cycles = analyze_core_components(backend_module_graph, \"Backend\")\n",
    "frontend_core, frontend_cycles = analyze_core_components(frontend_module_graph, \"Frontend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Architectural Layers\n",
    "\n",
    "Now let's create a layered architectural view by analyzing the dependencies between modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def identify_layers(graph):\n",
    "    \"\"\"Identify architectural layers based on dependencies.\"\"\"\n",
    "    temp_graph = graph.copy()\n",
    "    layers = []\n",
    "    remaining_nodes = set(temp_graph.nodes())\n",
    "    \n",
    "    while remaining_nodes:\n",
    "        bottom_layer = []\n",
    "        for node in remaining_nodes:\n",
    "            has_remaining = any(succ in remaining_nodes and succ != node for succ in temp_graph.successors(node))\n",
    "            if not has_remaining:\n",
    "                bottom_layer.append(node)\n",
    "        \n",
    "        if not bottom_layer:\n",
    "            out_degrees = {node: temp_graph.out_degree(node) for node in remaining_nodes}\n",
    "            bottom_layer = [min(out_degrees, key=out_degrees.get)]\n",
    "        \n",
    "        layers.append(bottom_layer)\n",
    "        remaining_nodes -= set(bottom_layer)\n",
    "    \n",
    "    return list(reversed(layers))\n",
    "\n",
    "def plot_layered_architecture(graph, layers, title, output_file):\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    pos = {}\n",
    "    for i, layer in enumerate(layers):\n",
    "        layer_height = 1.0 - (i / len(layers))\n",
    "        for j, node in enumerate(sorted(layer)):\n",
    "            layer_width = len(layer)\n",
    "            pos[node] = (j / (layer_width - 1) if layer_width > 1 else 0.5, layer_height)\n",
    "    for node in pos:\n",
    "        x, y = pos[node]\n",
    "        pos[node] = (x * 10 - 5, y * 8 - 4)\n",
    "    \n",
    "    layer_colors = plt.cm.viridis(np.linspace(0, 1, len(layers)))\n",
    "    for i, layer in enumerate(layers):\n",
    "        nx.draw_networkx_nodes(graph, pos, nodelist=layer, \n",
    "                               node_color=[layer_colors[i]] * len(layer), node_size=2000, alpha=0.8)\n",
    "    nx.draw_networkx_edges(graph, pos, arrows=True, alpha=0.4, connectionstyle='arc3,rad=0.1')\n",
    "    nx.draw_networkx_labels(graph, pos, font_size=9, font_weight='bold')\n",
    "    for i, layer in enumerate(layers):\n",
    "        layer_y = (1.0 - (i / len(layers))) * 8 - 4\n",
    "        plt.text(-6.5, layer_y, f\"Layer {len(layers)-i}\", fontsize=12, fontweight='bold')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return pos\n",
    "\n",
    "# Identify and visualize layers for backend\n",
    "backend_layers = identify_layers(backend_module_graph)\n",
    "print(\"\\n===== Backend Architectural Layers =====\\n\")\n",
    "for i, layer in enumerate(backend_layers, 1):\n",
    "    print(f\"Layer {i}: {', '.join(sorted(layer))}\")\n",
    "plot_layered_architecture(backend_module_graph, backend_layers, \"Zeeguu Backend - Layered Architecture View\", \"backend_layered_architecture.png\")\n",
    "\n",
    "# Identify and visualize layers for frontend\n",
    "frontend_layers = identify_layers(frontend_module_graph)\n",
    "print(\"\\n===== Frontend Architectural Layers =====\\n\")\n",
    "for i, layer in enumerate(frontend_layers, 1):\n",
    "    print(f\"Layer {i}: {', '.join(sorted(layer))}\")\n",
    "plot_layered_architecture(frontend_module_graph, frontend_layers, \"Zeeguu Frontend - Layered Architecture View\", \"frontend_layered_architecture.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Component Dependencies Analysis\n",
    "\n",
    "Let's try to identify dependencies between backend and frontend components by analyzing API endpoints and API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cross_component_dependencies():\n",
    "    \"\"\"Analyze dependencies between backend and frontend components.\"\"\"\n",
    "    print(\"\\n===== Cross-Component Dependencies Analysis =====\\n\")\n",
    "    \n",
    "    import re\n",
    "    backend_files = glob.glob(os.path.join(BACKEND_DIR, '**', '*.py'), recursive=True)\n",
    "    frontend_files = glob.glob(os.path.join(FRONTEND_DIR, '**', '*.py'), recursive=True)\n",
    "    \n",
    "    # Pattern for API endpoints in backend\n",
    "    api_endpoint_pattern = re.compile(r'@(api\\.route|route)\\([\\\"\\']([^\\\"\\']+)[\\\"\\']')\n",
    "    # Pattern for API calls in frontend\n",
    "    api_call_pattern = re.compile(r'(fetch|axios\\.get)\\([\\\"\\']([^\\\"\\']*api[^\\\"\\']*)[\\\"\\']')\n",
    "    \n",
    "    endpoints = []\n",
    "    for file_path in backend_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                matches = api_endpoint_pattern.findall(content)\n",
    "                for match in matches:\n",
    "                    endpoints.append(match[1])\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    print(f\"Found {len(endpoints)} API endpoints in backend code\")\n",
    "    if endpoints:\n",
    "        print(\"Sample endpoints:\")\n",
    "        for endpoint in endpoints[:5]:\n",
    "            print(f\"  {endpoint}\")\n",
    "    \n",
    "    api_calls = []\n",
    "    frontend_modules_with_api_calls = set()\n",
    "    for file_path in frontend_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                matches = api_call_pattern.findall(content)\n",
    "                if matches:\n",
    "                    module_name = os.path.basename(file_path).split('.')[0]\n",
    "                    frontend_modules_with_api_calls.add(module_name)\n",
    "                    for match in matches:\n",
    "                        api_call = match[1]\n",
    "                        if api_call:\n",
    "                            api_calls.append((module_name, api_call))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    print(f\"\\nFound {len(api_calls)} API calls in frontend code\")\n",
    "    print(f\"Frontend modules making API calls: {len(frontend_modules_with_api_calls)}\")\n",
    "    if api_calls:\n",
    "        print(\"Sample API calls (module, endpoint):\")\n",
    "        for module, endpoint in api_calls[:5]:\n",
    "            print(f\"  {module} â†’ {endpoint}\")\n",
    "    return endpoints, api_calls, frontend_modules_with_api_calls\n",
    "\n",
    "endpoints, api_calls, frontend_api_modules = analyze_cross_component_dependencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Combined View\n",
    "\n",
    "Let's create a combined architecture view for backend and frontend components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_architecture_view(backend_graph, frontend_graph, frontend_api_modules):\n",
    "    \"\"\"Create a combined view of backend and frontend architecture.\"\"\"\n",
    "    combined_graph = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes with prefixes\n",
    "    for node in backend_graph.nodes():\n",
    "        combined_graph.add_node(f\"BE:{node}\", component=\"backend\")\n",
    "    for node in frontend_graph.nodes():\n",
    "        combined_graph.add_node(f\"FE:{node}\", component=\"frontend\")\n",
    "    \n",
    "    # Add internal edges\n",
    "    for src, dst in backend_graph.edges():\n",
    "        combined_graph.add_edge(f\"BE:{src}\", f\"BE:{dst}\")\n",
    "    for src, dst in frontend_graph.edges():\n",
    "        combined_graph.add_edge(f\"FE:{src}\", f\"FE:{dst}\")\n",
    "    \n",
    "    # Connect frontend modules making API calls to top 3 backend core modules\n",
    "    for module in frontend_api_modules:\n",
    "        for i, (backend_module, _) in enumerate(backend_core):\n",
    "            if i < 3:\n",
    "                combined_graph.add_edge(f\"FE:{module}\", f\"BE:{backend_module}\", style=\"dashed\", color=\"red\")\n",
    "    return combined_graph\n",
    "\n",
    "def visualize_combined_architecture(graph):\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    backend_nodes = [n for n in graph.nodes() if n.startswith(\"BE:\")]\n",
    "    frontend_nodes = [n for n in graph.nodes() if n.startswith(\"FE:\")]\n",
    "    pos = {}\n",
    "    backend_pos = nx.circular_layout(graph.subgraph(backend_nodes))\n",
    "    for node, (x, y) in backend_pos.items():\n",
    "        pos[node] = (x - 3, y)\n",
    "    frontend_pos = nx.circular_layout(graph.subgraph(frontend_nodes))\n",
    "    for node, (x, y) in frontend_pos.items():\n",
    "        pos[node] = (x + 3, y)\n",
    "    \n",
    "    nx.draw_networkx_nodes(graph, pos, nodelist=backend_nodes, node_color='skyblue', node_size=1500, alpha=0.8)\n",
    "    nx.draw_networkx_nodes(graph, pos, nodelist=frontend_nodes, node_color='lightgreen', node_size=1500, alpha=0.8)\n",
    "    \n",
    "    internal_edges = []\n",
    "    cross_edges = []\n",
    "    for u, v in graph.edges():\n",
    "        if (u.startswith(\"BE:\") and v.startswith(\"BE:\")) or (u.startswith(\"FE:\") and v.startswith(\"FE:\")):\n",
    "            internal_edges.append((u, v))\n",
    "        else:\n",
    "            cross_edges.append((u, v))\n",
    "    nx.draw_networkx_edges(graph, pos, edgelist=internal_edges, alpha=0.3, arrows=True)\n",
    "    nx.draw_networkx_edges(graph, pos, edgelist=cross_edges, edge_color='red', style='dashed', alpha=0.7, arrows=True, width=2, connectionstyle='arc3,rad=0.2')\n",
    "    labels = {node: node.split(\":\")[1] for node in graph.nodes()}\n",
    "    nx.draw_networkx_labels(graph, pos, labels=labels, font_size=8, font_weight='bold')\n",
    "    plt.plot([0], [0], color='skyblue', marker='o', markersize=15, label='Backend Components', linestyle='None')\n",
    "    plt.plot([0], [0], color='lightgreen', marker='o', markersize=15, label='Frontend Components', linestyle='None')\n",
    "    plt.plot([0], [0], color='red', linestyle='--', linewidth=2, label='API Calls')\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "    plt.title(\"Combined Architecture View: Backend and Frontend Integration\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('combined_architecture.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "combined_graph = create_combined_architecture_view(backend_module_graph, frontend_module_graph, frontend_api_modules)\n",
    "visualize_combined_architecture(combined_graph)\n",
    "\n",
    "print(\"\\n===== Combined Architecture Statistics =====\\n\")\n",
    "print(f\"Total nodes: {combined_graph.number_of_nodes()}\")\n",
    "print(f\"Total edges: {combined_graph.number_of_edges()}\")\n",
    "backend_nodes = [node for node in combined_graph.nodes() if node.startswith(\"BE:\")]\n",
    "frontend_nodes = [node for node in combined_graph.nodes() if node.startswith(\"FE:\")]\n",
    "print(f\"Backend components: {len(backend_nodes)}\")\n",
    "print(f\"Frontend components: {len(frontend_nodes)}\")\n",
    "cross_edges = [(u, v) for u, v in combined_graph.edges() if (u.startswith(\"BE:\") and v.startswith(\"FE:\")) or (u.startswith(\"FE:\") and v.startswith(\"BE:\"))]\n",
    "print(f\"Cross-component connections: {len(cross_edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Analysis: Identifying Architectural Smells\n",
    "\n",
    "Let's analyze the architecture for potential code smells or design issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_architectural_smells(graph, name):\n",
    "    \"\"\"Identify potential architectural smells or issues.\"\"\"\n",
    "    print(f\"\\n===== Architectural Smell Analysis for {name} =====\\n\")\n",
    "    \n",
    "    node_count = graph.number_of_nodes()\n",
    "    edge_count = graph.number_of_edges()\n",
    "    density = nx.density(graph)\n",
    "    \n",
    "    smells = []\n",
    "    \n",
    "    # 1. Cyclic Dependencies\n",
    "    cycles = list(nx.simple_cycles(graph))\n",
    "    if cycles:\n",
    "        smell = {\n",
    "            'name': 'Cyclic Dependencies',\n",
    "            'description': 'Modules that depend on each other in a circular manner',\n",
    "            'severity': 'High',\n",
    "            'examples': cycles[:3],\n",
    "            'recommendation': 'Consider introducing abstractions or applying dependency inversion principles'\n",
    "        }\n",
    "        smells.append(smell)\n",
    "    \n",
    "    # 2. Highly Connected Modules (Hub-like)\n",
    "    out_degree = {node: graph.out_degree(node) for node in graph.nodes()}\n",
    "    in_degree = {node: graph.in_degree(node) for node in graph.nodes()}\n",
    "    avg_out_degree = sum(out_degree.values()) / max(1, len(out_degree))\n",
    "    avg_in_degree = sum(in_degree.values()) / max(1, len(in_degree))\n",
    "    hub_threshold = 3 * avg_out_degree\n",
    "    hub_modules = [node for node, degree in out_degree.items() if degree > hub_threshold and degree > 5]\n",
    "    if hub_modules:\n",
    "        smell = {\n",
    "            'name': 'Hub-like Modules',\n",
    "            'description': 'Modules with excessive outgoing dependencies',\n",
    "            'severity': 'Medium',\n",
    "            'examples': [(node, out_degree[node]) for node in hub_modules[:3]],\n",
    "            'recommendation': 'Consider breaking down these modules into smaller, more focused components'\n",
    "        }\n",
    "        smells.append(smell)\n",
    "    \n",
    "    bottleneck_threshold = 3 * avg_in_degree\n",
    "    bottleneck_modules = [node for node, degree in in_degree.items() if degree > bottleneck_threshold and degree > 5]\n",
    "    if bottleneck_modules:\n",
    "        smell = {\n",
    "            'name': 'Bottleneck Modules',\n",
    "            'description': 'Modules that are depended upon by many others',\n",
    "            'severity': 'Medium' if len(bottleneck_modules) < 5 else 'High',\n",
    "            'examples': [(node, in_degree[node]) for node in bottleneck_modules[:3]],\n",
    "            'recommendation': 'Ensure these modules have clear, well-defined responsibilities'\n",
    "        }\n",
    "        smells.append(smell)\n",
    "    \n",
    "    isolated = [node for node in graph.nodes() if graph.degree(node) == 0]\n",
    "    if isolated:\n",
    "        smell = {\n",
    "            'name': 'Isolated Components',\n",
    "            'description': 'Modules with no connections to the rest of the system',\n",
    "            'severity': 'Low',\n",
    "            'examples': isolated[:5],\n",
    "            'recommendation': 'Verify if these are unused or if dependency analyses are incomplete'\n",
    "        }\n",
    "        smells.append(smell)\n",
    "    \n",
    "    if density > 0.2:\n",
    "        smell = {\n",
    "            'name': 'Excessive Module Coupling',\n",
    "            'description': 'The architecture has high connectivity between modules',\n",
    "            'severity': 'High' if density > 0.3 else 'Medium',\n",
    "            'examples': [f'Graph density: {density:.4f}'],\n",
    "            'recommendation': 'Introduce more abstraction layers and better separation of concerns'\n",
    "        }\n",
    "        smells.append(smell)\n",
    "    \n",
    "    if smells:\n",
    "        print(f\"Detected {len(smells)} potential architectural issues:\")\n",
    "        for i, smell in enumerate(smells, 1):\n",
    "            print(f\"\\n{i}. {smell['name']} (Severity: {smell['severity']})\")\n",
    "            print(f\"   Description: {smell['description']}\")\n",
    "            print(\"   Examples:\")\n",
    "            for ex in smell['examples']:\n",
    "                print(f\"     - {ex}\")\n",
    "            print(f\"   Recommendation: {smell['recommendation']}\")\n",
    "    else:\n",
    "        print(\"No significant architectural issues detected.\")\n",
    "    return smells\n",
    "\n",
    "backend_smells = identify_architectural_smells(backend_module_graph, \"Backend\")\n",
    "frontend_smells = identify_architectural_smells(frontend_module_graph, \"Frontend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Dependency Matrix\n",
    "\n",
    "A Dependency Structure Matrix (DSM) provides a compact view of dependencies between modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dependency_matrix(graph, name):\n",
    "    \"\"\"Create and visualize a Dependency Structure Matrix (DSM).\"\"\"\n",
    "    nodes = sorted(graph.nodes())\n",
    "    n = len(nodes)\n",
    "    matrix = np.zeros((n, n))\n",
    "    node_to_idx = {node: i for i, node in enumerate(nodes)}\n",
    "    for src, dst in graph.edges():\n",
    "        matrix[node_to_idx[src], node_to_idx[dst]] = 1\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(matrix, cmap='Blues', interpolation='nearest')\n",
    "    if n <= 30:\n",
    "        plt.xticks(range(n), nodes, rotation=90, fontsize=8)\n",
    "        plt.yticks(range(n), nodes, fontsize=8)\n",
    "    else:\n",
    "        step = max(1, n // 30)\n",
    "        plt.xticks(range(0, n, step), [nodes[i] for i in range(0, n, step)], rotation=90, fontsize=8)\n",
    "        plt.yticks(range(0, n, step), [nodes[i] for i in range(0, n, step)], fontsize=8)\n",
    "    plt.title(f'{name} Dependency Structure Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "    plt.savefig(f'{name.lower()}_dsm.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return matrix, nodes\n",
    "\n",
    "backend_dsm, backend_dsm_nodes = create_dependency_matrix(backend_module_graph, \"Backend\")\n",
    "frontend_dsm, frontend_dsm_nodes = create_dependency_matrix(frontend_module_graph, \"Frontend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summarize Architectural Insights\n",
    "\n",
    "Let's summarize the key architectural insights discovered from our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_architectural_insights():\n",
    "    print(\"\\n===== Zeeguu Architecture Reconstruction Summary =====\\n\")\n",
    "    \n",
    "    print(\"Backend Architecture:\")\n",
    "    print(f\"  - Total modules: {backend_module_graph.number_of_nodes()}\")\n",
    "    print(f\"  - Total dependencies: {backend_module_graph.number_of_edges()}\")\n",
    "    print(f\"  - Architectural layers: {len(backend_layers)}\")\n",
    "    print(\"  - Core modules:\")\n",
    "    for module, cent in backend_core:\n",
    "        print(f\"    * {module} (centrality: {cent:.4f})\")\n",
    "    \n",
    "    print(\"\\nFrontend Architecture:\")\n",
    "    print(f\"  - Total modules: {frontend_module_graph.number_of_nodes()}\")\n",
    "    print(f\"  - Total dependencies: {frontend_module_graph.number_of_edges()}\")\n",
    "    print(f\"  - Architectural layers: {len(frontend_layers)}\")\n",
    "    print(\"  - Core modules:\")\n",
    "    for module, cent in frontend_core:\n",
    "        print(f\"    * {module} (centrality: {cent:.4f})\")\n",
    "    \n",
    "    print(\"\\nCross-Component Integration:\")\n",
    "    print(f\"  - API endpoints identified: {len(endpoints)}\")\n",
    "    print(f\"  - Frontend modules making API calls: {len(frontend_api_modules)}\")\n",
    "    \n",
    "    print(\"\\nKey Architectural Observations:\")\n",
    "    observations = [\n",
    "        \"The backend exhibits a layered architecture with clear separation of concerns.\",\n",
    "        f\"The core backend module appears to be {backend_core[0][0] if backend_core else 'unknown'}.\",\n",
    "        f\"The core frontend module appears to be {frontend_core[0][0] if frontend_core else 'unknown'}.\",\n",
    "        f\"Backend has {len(backend_cycles)} potential cycles that might benefit from refactoring.\",\n",
    "        f\"Frontend has {len(frontend_cycles)} potential cycles.\"\n",
    "    ]\n",
    "    for i, obs in enumerate(observations, 1):\n",
    "        print(f\"  {i}. {obs}\")\n",
    "    \n",
    "    print(\"\\nArchitectural Recommendations:\")\n",
    "    recommendations = []\n",
    "    if backend_smells:\n",
    "        for smell in backend_smells:\n",
    "            recommendations.append(f\"Backend {smell['name']}: {smell['recommendation']}\")\n",
    "    if frontend_smells:\n",
    "        for smell in frontend_smells:\n",
    "            recommendations.append(f\"Frontend {smell['name']}: {smell['recommendation']}\")\n",
    "    recommendations.extend([\n",
    "        \"Consider documenting the identified architectural layers.\",\n",
    "        \"Formalize API contracts between frontend and backend.\",\n",
    "        \"Introduce architectural fitness functions to prevent degradation.\"\n",
    "    ])\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"  {i}. {rec}\")\n",
    "\n",
    "summarize_architectural_insights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Results for Report\n",
    "\n",
    "Finally, let's export key data and visualizations for inclusion in the architecture reconstruction report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def export_results():\n",
    "    print(\"\\n===== Exporting Results =====\\n\")\n",
    "    results_dir = 'architecture_results'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # List of images to export\n",
    "    images = [\n",
    "        'backend_module_graph.png',\n",
    "        'frontend_module_graph.png',\n",
    "        'backend_layered_architecture.png',\n",
    "        'frontend_layered_architecture.png',\n",
    "        'combined_architecture.png',\n",
    "        'backend_dsm.png',\n",
    "        'frontend_dsm.png'\n",
    "    ]\n",
    "    \n",
    "    for img in images:\n",
    "        if os.path.exists(img):\n",
    "            shutil.copy(img, results_dir)\n",
    "        else:\n",
    "            print(f\"Warning: {img} not found.\")\n",
    "    \n",
    "    report_data = {\n",
    "        'backend': {\n",
    "            'modules': list(backend_module_graph.nodes()),\n",
    "            'dependencies': list(backend_module_graph.edges()),\n",
    "            'core_modules': backend_core,\n",
    "            'layers': backend_layers,\n",
    "            'architectural_smells': backend_smells\n",
    "        },\n",
    "        'frontend': {\n",
    "            'modules': list(frontend_module_graph.nodes()),\n",
    "            'dependencies': list(frontend_module_graph.edges()),\n",
    "            'core_modules': frontend_core,\n",
    "            'layers': frontend_layers,\n",
    "            'architectural_smells': frontend_smells\n",
    "        },\n",
    "        'cross_component': {\n",
    "            'api_endpoints': endpoints,\n",
    "            'frontend_modules_with_api_calls': list(frontend_api_modules)\n",
    "        }\n",
    "    }\n",
    "    with open(os.path.join(results_dir, 'report_data.json'), 'w') as f:\n",
    "        import json\n",
    "        json.dump(report_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Results exported to '{results_dir}' directory\")\n",
    "    print(\"The following files are available for your report:\")\n",
    "    for file in os.listdir(results_dir):\n",
    "        print(f\"  {file}\")\n",
    "\n",
    "export_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "In this notebook, we've performed a comprehensive architecture reconstruction of the Zeeguu system using Pyan. We generated multiple architectural views including:\n",
    "\n",
    "- Basic call graphs for backend and frontend components\n",
    "- Higher-level module dependency views\n",
    "- Layered architecture visualizations\n",
    "- A combined architecture view integrating backend and frontend\n",
    "- Dependency Structure Matrices (DSM)\n",
    "- Identification of potential architectural smells\n",
    "\n",
    "These insights form a solid foundation for the architecture reconstruction report and provide data-driven recommendations for improving system design."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
