{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Reconstruction for Zeeguu\n",
    "\n",
    "This notebook provides a comprehensive architecture reconstruction for the Zeeguu system, analyzing both the backend API (`../Data/api`) and frontend (`../Data/frontend`). The goal is to extract meaningful architectural views that provide insights into the system's structure, dependencies, and complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "Install all the necessary packages for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install prospector pylint pydepend networkx matplotlib pyyaml jinja2 pandas pyreverse graphviz pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Setup\n",
    "\n",
    "Define paths and configuration options for the analysis. Note that, since this notebook is in `Root/Tools`, the project paths are defined relative to that location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, Image\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths relative to the notebook location (Root/Tools)\n",
    "API_PATH = os.path.join('..', 'Data', 'api')\n",
    "FRONTEND_PATH = os.path.join('..', 'Data', 'frontend')\n",
    "OUTPUT_DIR = 'architecture_analysis'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Backend path set to: {API_PATH}\")\n",
    "print(f\"Frontend path set to: {FRONTEND_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic System Information\n",
    "\n",
    "Extract basic information about the system to understand its size and scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_and_lines(path, extensions=None):\n",
    "    \"\"\"\n",
    "    Count files and lines of code in the given path, filtered by file extensions.\n",
    "    \"\"\"\n",
    "    if extensions is None:\n",
    "        extensions = ['.py', '.js', '.jsx', '.ts', '.tsx']\n",
    "    \n",
    "    file_count = 0\n",
    "    line_count = 0\n",
    "    files_by_ext = {ext: 0 for ext in extensions}\n",
    "    lines_by_ext = {ext: 0 for ext in extensions}\n",
    "    \n",
    "    for root, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            _, ext = os.path.splitext(file)\n",
    "            if ext in extensions:\n",
    "                file_count += 1\n",
    "                files_by_ext[ext] += 1\n",
    "                \n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        lines = len(f.readlines())\n",
    "                        line_count += lines\n",
    "                        lines_by_ext[ext] += lines\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'total_files': file_count,\n",
    "        'total_lines': line_count,\n",
    "        'files_by_ext': files_by_ext,\n",
    "        'lines_by_ext': lines_by_ext\n",
    "    }\n",
    "\n",
    "# Analyze backend\n",
    "backend_stats = count_files_and_lines(API_PATH)\n",
    "print(\"Backend Statistics:\")\n",
    "print(json.dumps(backend_stats, indent=2))\n",
    "\n",
    "# Analyze frontend\n",
    "frontend_stats = count_files_and_lines(FRONTEND_PATH)\n",
    "print(\"\\nFrontend Statistics:\")\n",
    "print(json.dumps(frontend_stats, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Code Quality Analysis with Prospector\n",
    "\n",
    "Run a comprehensive code quality analysis using Prospector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prospector(path, output_file):\n",
    "    \"\"\"\n",
    "    Run Prospector on the specified path and save results to output_file.\n",
    "    Returns a summary of findings.\n",
    "    \"\"\"\n",
    "    full_output_path = os.path.join(OUTPUT_DIR, output_file)\n",
    "    \n",
    "    # Run prospector and capture its JSON output\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['prospector', path, '--output-format=json'], \n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        \n",
    "        # Write the output to a file\n",
    "        with open(full_output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(result.stdout)\n",
    "        \n",
    "        print(f\"Prospector analysis completed for {path}\")\n",
    "        \n",
    "        # Load and parse the results\n",
    "        results = json.loads(result.stdout)\n",
    "        messages = results.get('messages', [])\n",
    "        tools_used = results.get('tools', [])\n",
    "        summary = {\n",
    "            'total_issues': len(messages),\n",
    "            'tools_used': tools_used,\n",
    "            'issues_by_type': {}\n",
    "        }\n",
    "        \n",
    "        for msg in messages:\n",
    "            msg_type = msg.get('source')\n",
    "            if msg_type not in summary['issues_by_type']:\n",
    "                summary['issues_by_type'][msg_type] = 0\n",
    "            summary['issues_by_type'][msg_type] += 1\n",
    "            \n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error running Prospector on {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run Prospector on backend\n",
    "backend_prospector = run_prospector(API_PATH, 'api_prospector_report.json')\n",
    "print(\"\\nBackend Prospector Summary:\")\n",
    "print(json.dumps(backend_prospector, indent=2))\n",
    "\n",
    "# Run Prospector on frontend\n",
    "frontend_prospector = run_prospector(FRONTEND_PATH, 'frontend_prospector_report.json')\n",
    "print(\"\\nFrontend Prospector Summary:\")\n",
    "print(json.dumps(frontend_prospector, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Module Dependency Analysis\n",
    "\n",
    "Extract and visualize module dependencies using PyDepend for the backend and a custom import parser for the frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dependencies(path, is_backend=True):\n",
    "    \"\"\"\n",
    "    Extract module dependencies from the given path.\n",
    "    For the backend (Python), use pydepend.\n",
    "    For the frontend (JavaScript/React), parse import statements.\n",
    "    \"\"\"\n",
    "    if is_backend:\n",
    "        output_path = os.path.join(OUTPUT_DIR, 'api_dependencies.dot')\n",
    "        cmd = ['pydepend', '--ext-direct=dot', '-o', output_path, path]\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(cmd, check=True)\n",
    "            print(f\"Dependency extraction completed for {path}\")\n",
    "            \n",
    "            # Parse the dot file to create a NetworkX graph\n",
    "            G = nx.drawing.nx_pydot.read_dot(output_path)\n",
    "            return G\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting dependencies for {path}: {e}\")\n",
    "            # Fallback: use pyreverse\n",
    "            try:\n",
    "                output_prefix = os.path.join(OUTPUT_DIR, 'api_dependencies')\n",
    "                cmd = ['pyreverse', '-o', 'dot', '-p', 'zeeguu', path]\n",
    "                subprocess.run(cmd, check=True)\n",
    "                # pyreverse creates classes.dot and packages.dot\n",
    "                G = nx.drawing.nx_pydot.read_dot('classes.dot')\n",
    "                os.rename('classes.dot', os.path.join(OUTPUT_DIR, 'classes.dot'))\n",
    "                os.rename('packages.dot', os.path.join(OUTPUT_DIR, 'packages.dot'))\n",
    "                return G\n",
    "            except Exception as e2:\n",
    "                print(f\"Error using pyreverse: {e2}\")\n",
    "                return nx.DiGraph()\n",
    "    else:\n",
    "        # For the frontend, use a custom parser for import statements\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        import re\n",
    "        import_patterns = [\n",
    "            (r\"import\\s+([\\w\\s,{}]+)\\s+from\\s+['\\\"](.*)['\\\"]\", lambda m: (m.group(2), m.group(1))),\n",
    "            (r\"import\\s+['\\\"](.*)['\\\"]\", lambda m: (m.group(1), None))\n",
    "        ]\n",
    "        \n",
    "        for root, _, files in os.walk(path):\n",
    "            for file in files:\n",
    "                if file.endswith(('.js', '.jsx', '.ts', '.tsx')):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    rel_path = os.path.relpath(file_path, path)\n",
    "                    \n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                            content = f.read()\n",
    "                            \n",
    "                            for pattern, extractor in import_patterns:\n",
    "                                for match in re.finditer(pattern, content):\n",
    "                                    imported_module, _ = extractor(match)\n",
    "                                    \n",
    "                                    # Skip external dependencies (non-relative imports)\n",
    "                                    if not imported_module.startswith('.'):\n",
    "                                        continue\n",
    "                                    \n",
    "                                    # Normalize relative path\n",
    "                                    target_path = os.path.normpath(os.path.join(os.path.dirname(rel_path), imported_module))\n",
    "                                    G.add_edge(rel_path, target_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error parsing {file_path}: {e}\")\n",
    "        \n",
    "        return G\n",
    "\n",
    "# Extract backend dependencies\n",
    "try:\n",
    "    backend_deps = extract_dependencies(API_PATH, is_backend=True)\n",
    "    print(f\"Backend dependency graph has {backend_deps.number_of_nodes()} nodes and {backend_deps.number_of_edges()} edges\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not extract backend dependencies: {e}\")\n",
    "    backend_deps = nx.DiGraph()\n",
    "\n",
    "# Extract frontend dependencies\n",
    "try:\n",
    "    frontend_deps = extract_dependencies(FRONTEND_PATH, is_backend=False)\n",
    "    print(f\"Frontend dependency graph has {frontend_deps.number_of_nodes()} nodes and {frontend_deps.number_of_edges()} edges\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not extract frontend dependencies: {e}\")\n",
    "    frontend_deps = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizing Dependency Graphs\n",
    "\n",
    "Below is a simple visualization of the dependency graphs for the backend and frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dependency_graph(G, title=\"Dependency Graph\", figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Draws a directed dependency graph using matplotlib.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
    "    nx.draw(G, pos, with_labels=True, node_size=500, arrowstyle='->', arrowsize=10)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize backend dependencies if available\n",
    "if backend_deps.number_of_nodes() > 0:\n",
    "    draw_dependency_graph(backend_deps, title=\"Backend Dependency Graph\")\n",
    "else:\n",
    "    print(\"No backend dependency graph to display.\")\n",
    "\n",
    "# Visualize frontend dependencies if available\n",
    "if frontend_deps.number_of_nodes() > 0:\n",
    "    draw_dependency_graph(frontend_deps, title=\"Frontend Dependency Graph\")\n",
    "else:\n",
    "    print(\"No frontend dependency graph to display.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
