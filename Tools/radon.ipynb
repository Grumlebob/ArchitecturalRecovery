{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeeguu Architecture Reconstruction - Basic Radon Analysis\n",
    "\n",
    "This notebook provides a comprehensive analysis of the Zeeguu API (backend) and Frontend code using Radon – a Python tool for computing various code metrics. We will extract architectural insights using metrics such as:\n",
    "\n",
    "1. **Cyclomatic Complexity (CC):** Identifies overly complex functions.\n",
    "2. **Maintainability Index (MI):** Evaluates overall maintainability of modules.\n",
    "3. **Raw Metrics:** Counts lines of code (LOC, LLOC, SLOC) and comment ratios.\n",
    "4. **Halstead Metrics:** Advanced metrics based on operands and operators.\n",
    "\n",
    "These metrics will help us construct various architectural viewpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "        print(f\"{package} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install radon and additional packages for visualization\n",
    "install_package('radon')\n",
    "install_package('matplotlib')\n",
    "install_package('pandas')\n",
    "install_package('networkx')\n",
    "install_package('pydot')\n",
    "install_package('squarify')\n",
    "\n",
    "# Verify Radon installation by printing its version\n",
    "try:\n",
    "    subprocess.check_call([\"radon\", \"--version\"])\n",
    "except Exception as e:\n",
    "    print(\"Error calling radon. Please ensure it is installed properly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Project Structure Analysis\n",
    "\n",
    "We'll begin by listing the directory structures for both the API and Frontend. On Windows, we replace the Unix shell commands with Python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API (Backend) Structure:\n",
      "data\\api\\\n",
      "data\\api\\subdir_example\n",
      "\n",
      "Frontend Structure:\n",
      "data\\frontend\\\n",
      "data\\frontend\\subdir_example\n"
     ]
    }
   ],
   "source": [
    "def list_directories(root_dir):\n",
    "    dirs = []\n",
    "    for dirpath, dirnames, _ in os.walk(root_dir):\n",
    "        # Exclude hidden directories\n",
    "        dirnames[:] = [d for d in dirnames if not d.startswith('.')]\n",
    "        dirs.append(os.path.relpath(dirpath, root_dir))\n",
    "    return sorted(dirs)\n",
    "\n",
    "print(\"API (Backend) Structure:\")\n",
    "for d in list_directories(os.path.join('data', 'api')):\n",
    "    print(d)\n",
    "\n",
    "print(\"\\nFrontend Structure:\")\n",
    "for d in list_directories(os.path.join('data', 'frontend')):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Python files in API (Backend):  15\n",
      "Number of Python files in Frontend:  10\n"
     ]
    }
   ],
   "source": [
    "def count_python_files(root_dir):\n",
    "    count = 0\n",
    "    for dirpath, _, files in os.walk(root_dir):\n",
    "        for f in files:\n",
    "            if f.endswith('.py'):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "api_count = count_python_files(os.path.join('data', 'api'))\n",
    "frontend_count = count_python_files(os.path.join('data', 'frontend'))\n",
    "\n",
    "print(\"Number of Python files in API (Backend): \", api_count)\n",
    "print(\"Number of Python files in Frontend: \", frontend_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cyclomatic Complexity Analysis\n",
    "\n",
    "Cyclomatic complexity (CC) helps identify modules that might be too complex. We run Radon on both the API and Frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"API Cyclomatic Complexity:\")\n",
    "subprocess.check_call([\"radon\", \"cc\", os.path.join('data', 'api'), \"-s\", \"-a\"])\n",
    "\n",
    "print(\"\\nFrontend Cyclomatic Complexity:\")\n",
    "subprocess.check_call([\"radon\", \"cc\", os.path.join('data', 'frontend'), \"-s\", \"-a\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Maintainability Index Analysis\n",
    "\n",
    "The Maintainability Index (MI) provides a composite view of code maintainability. Higher values indicate better maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"API Maintainability Index:\")\n",
    "subprocess.check_call([\"radon\", \"mi\", os.path.join('data', 'api')])\n",
    "\n",
    "print(\"\\nFrontend Maintainability Index:\")\n",
    "subprocess.check_call([\"radon\", \"mi\", os.path.join('data', 'frontend')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Cyclomatic Complexity Analysis\n",
    "\n",
    "Identify the most complex files that might represent key architectural components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 Most Complex Files in API:\")\n",
    "subprocess.run([\"radon\", \"cc\", os.path.join('data', 'api'), \"-s\", \"-n\", \"C\", \"-o\", \"SCORE\"], shell=True)\n",
    "\n",
    "print(\"\\nTop 10 Most Complex Files in Frontend:\")\n",
    "subprocess.run([\"radon\", \"cc\", os.path.join('data', 'frontend'), \"-s\", \"-n\", \"C\", \"-o\", \"SCORE\"], shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Raw Metrics Analysis\n",
    "\n",
    "Raw metrics provide detailed statistics (LOC, LLOC, SLOC, etc.) which help us further understand the code size and commenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"API Raw Metrics:\")\n",
    "subprocess.check_call([\"radon\", \"raw\", os.path.join('data', 'api'), \"-s\"])\n",
    "\n",
    "print(\"\\nFrontend Raw Metrics:\")\n",
    "subprocess.check_call([\"radon\", \"raw\", os.path.join('data', 'frontend'), \"-s\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Halstead Metrics Analysis\n",
    "\n",
    "Halstead metrics provide an in-depth view of code complexity based on operands and operators. The following commands extract metrics for a sample of key files. (Adjust the file selection as needed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"API Halstead Metrics for Key Files:\")\n",
    "subprocess.run('for /F \"usebackq tokens=*\" %i in (`dir /B /S data\\api\\*.py`) do radon hal \"%i\"', shell=True)\n",
    "\n",
    "print(\"\\nFrontend Halstead Metrics for Key Files:\")\n",
    "subprocess.run('for /F \"usebackq tokens=*\" %i in (`dir /B /S data\\frontend\\*.py`) do radon hal \"%i\"', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radon Visualization\n",
    "\n",
    "In this section we process Radon’s output to create visualizations that help us understand the architectural complexity. We will extract data in JSON format, process it into Pandas DataFrames, and then generate bar charts, heatmaps, and treemaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def get_complexity_data(directory):\n",
    "    result = subprocess.run([\"radon\", \"cc\", directory, \"-j\"], capture_output=True, text=True)\n",
    "    try:\n",
    "        data = json.loads(result.stdout)\n",
    "        return data\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error parsing JSON output from radon\")\n",
    "        print(\"Output:\", result.stdout)\n",
    "        return {}\n",
    "\n",
    "api_complexity = get_complexity_data(os.path.join('data', 'api'))\n",
    "frontend_complexity = get_complexity_data(os.path.join('data', 'frontend'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_complexity_data(complexity_data):\n",
    "    rows = []\n",
    "    for filename, functions in complexity_data.items():\n",
    "        module_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "        package = os.path.basename(os.path.dirname(filename))\n",
    "        for func in functions:\n",
    "            rows.append({\n",
    "                'file': filename,\n",
    "                'module': module_name,\n",
    "                'package': package,\n",
    "                'function': func['name'],\n",
    "                'complexity': func['complexity'],\n",
    "                'rank': func['rank']\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "api_df = process_complexity_data(api_complexity)\n",
    "frontend_df = process_complexity_data(frontend_complexity)\n",
    "print(f\"API data contains {len(api_df)} function entries\")\n",
    "print(f\"Frontend data contains {len(frontend_df)} function entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Package-Level Complexity\n",
    "\n",
    "We create a bar chart that displays the average cyclomatic complexity per package. Only packages with at least 3 functions are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_package_complexity(df, title):\n",
    "    package_complexity = df.groupby('package')['complexity'].agg(['mean', 'count'])\n",
    "    package_complexity = package_complexity.sort_values('mean', ascending=False)\n",
    "    package_complexity = package_complexity[package_complexity['count'] >= 3]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.bar(package_complexity.index, package_complexity['mean'])\n",
    "    for i, bar in enumerate(bars):\n",
    "        complexity = package_complexity['mean'].iloc[i]\n",
    "        if complexity > 10:\n",
    "            bar.set_color('red')\n",
    "        elif complexity > 5:\n",
    "            bar.set_color('orange')\n",
    "        else:\n",
    "            bar.set_color('green')\n",
    "    plt.xlabel('Package')\n",
    "    plt.ylabel('Average Cyclomatic Complexity')\n",
    "    plt.title(f'{title} - Package Complexity')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    for i, bar in enumerate(bars):\n",
    "        count = package_complexity['count'].iloc[i]\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, f'n={count}', ha='center', va='bottom', fontsize=8)\n",
    "    return plt\n",
    "\n",
    "if not api_df.empty:\n",
    "    api_plot = visualize_package_complexity(api_df, 'API')\n",
    "    api_plot.savefig('api_package_complexity.png')\n",
    "    api_plot.show()\n",
    "else:\n",
    "    print(\"No API data available for visualization\")\n",
    "\n",
    "if not frontend_df.empty:\n",
    "    frontend_plot = visualize_package_complexity(frontend_df, 'Frontend')\n",
    "    frontend_plot.savefig('frontend_package_complexity.png')\n",
    "    frontend_plot.show()\n",
    "else:\n",
    "    print(\"No Frontend data available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squarify\n",
    "\n",
    "def create_complexity_treemap(df, title):\n",
    "    if df.empty:\n",
    "        print(f\"No data available for {title} treemap\")\n",
    "        return\n",
    "    module_complexity = df.groupby(['package', 'module'])['complexity'].sum().reset_index()\n",
    "    norm = plt.Normalize(module_complexity['complexity'].min(), module_complexity['complexity'].max())\n",
    "    colors = plt.cm.YlOrRd(norm(module_complexity['complexity']))\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    squarify.plot(sizes=module_complexity['complexity'], \n",
    "                  label=[f\"{row['package']}.{row['module']}\\n({row['complexity']:.1f})\" \n",
    "                         for _, row in module_complexity.iterrows()],\n",
    "                  color=colors, alpha=0.7, pad=True)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{title} - Module Complexity Distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{title.lower()}_module_treemap.png\")\n",
    "    plt.show()\n",
    "\n",
    "create_complexity_treemap(api_df, 'API')\n",
    "create_complexity_treemap(frontend_df, 'Frontend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Dependency Graph\n",
    "\n",
    "We now construct a module dependency graph by extracting import statements from each Python file. This helps us see how modules depend on one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def extract_imports(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        import_pattern = re.compile(r'^\\s*(?:from\\s+([\\w.]+)\\s+import\\s+|import\\s+([\\w.,\\s]+))', re.MULTILINE)\n",
    "        matches = import_pattern.findall(content)\n",
    "        imports = []\n",
    "        for from_import, direct_import in matches:\n",
    "            if from_import:\n",
    "                imports.append(from_import.split('.')[0])\n",
    "            elif direct_import:\n",
    "                for module in direct_import.split(','):\n",
    "                    cleaned = module.strip().split('.')[0]\n",
    "                    if cleaned:\n",
    "                        imports.append(cleaned)\n",
    "        return imports\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_python_files(directory):\n",
    "    return list(Path(directory).rglob('*.py'))\n",
    "\n",
    "def identify_project_modules(directory):\n",
    "    return {d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d)) and not d.startswith('.')}\n",
    "\n",
    "def create_module_graph(directory):\n",
    "    python_files = get_python_files(directory)\n",
    "    project_modules = identify_project_modules(directory)\n",
    "    for file in python_files:\n",
    "        if file.parent == Path(directory) or file.parent.parent == Path(directory):\n",
    "            module_name = file.stem\n",
    "            if not module_name.startswith('_'):\n",
    "                project_modules.add(module_name)\n",
    "    \n",
    "    import networkx as nx\n",
    "    G = nx.DiGraph()\n",
    "    for module in project_modules:\n",
    "        G.add_node(module)\n",
    "    \n",
    "    for file in python_files:\n",
    "        rel_path = file.relative_to(directory)\n",
    "        parts = rel_path.parts\n",
    "        if len(parts) == 1:\n",
    "            source_module = file.stem\n",
    "        else:\n",
    "            source_module = parts[0]\n",
    "        if file.name == '__init__.py':\n",
    "            continue\n",
    "        imports = extract_imports(file)\n",
    "        for imp in imports:\n",
    "            if imp in project_modules and imp != source_module:\n",
    "                if not G.has_edge(source_module, imp):\n",
    "                    G.add_edge(source_module, imp, weight=1)\n",
    "                else:\n",
    "                    G[source_module][imp]['weight'] += 1\n",
    "    return G\n",
    "\n",
    "api_graph = create_module_graph(os.path.join('data', 'api'))\n",
    "frontend_graph = create_module_graph(os.path.join('data', 'frontend'))\n",
    "\n",
    "def visualize_module_graph(G, title):\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    pos = nx.spring_layout(G, k=0.3, iterations=50)\n",
    "    centrality = nx.degree_centrality(G)\n",
    "    node_size = [v * 3000 + 200 for v in centrality.values()]\n",
    "    edge_weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "    max_weight = max(edge_weights) if edge_weights else 1\n",
    "    edge_width = [w/max_weight * 3 for w in edge_weights]\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=node_size, node_color='skyblue', alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, width=edge_width, alpha=0.6, edge_color='gray', arrowsize=15)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=10, font_weight='bold')\n",
    "    plt.title(f\"{title} Module Dependencies\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{title.lower()}_module_dependencies.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if len(api_graph.nodes()) > 0:\n",
    "    visualize_module_graph(api_graph, \"API\")\n",
    "else:\n",
    "    print(\"API graph has no nodes to visualize\")\n",
    "\n",
    "if len(frontend_graph.nodes()) > 0:\n",
    "    visualize_module_graph(frontend_graph, \"Frontend\")\n",
    "else:\n",
    "    print(\"Frontend graph has no nodes to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Complexity Heatmap for Core Modules\n",
    "\n",
    "We now create a horizontal bar chart (heatmap) that displays the average cyclomatic complexity per module for both the API and Frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_module_complexity(directory):\n",
    "    result = subprocess.run([\"radon\", \"cc\", directory, \"-j\"], capture_output=True, text=True)\n",
    "    try:\n",
    "        data = json.loads(result.stdout)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error parsing JSON output from radon for {directory}\")\n",
    "        return {}\n",
    "    module_complexity = {}\n",
    "    for file_path, functions in data.items():\n",
    "        path_parts = Path(file_path).parts\n",
    "        module = path_parts[1] if len(path_parts) > 1 else Path(file_path).stem\n",
    "        if module.startswith('_'):\n",
    "            continue\n",
    "        if functions:\n",
    "            avg_complexity = sum(func['complexity'] for func in functions) / len(functions)\n",
    "            if module not in module_complexity:\n",
    "                module_complexity[module] = {'sum': 0, 'count': 0}\n",
    "            module_complexity[module]['sum'] += avg_complexity\n",
    "            module_complexity[module]['count'] += 1\n",
    "    result_dict = {module: data['sum'] / data['count'] for module, data in module_complexity.items() if data['count'] > 0}\n",
    "    return result_dict\n",
    "\n",
    "api_mod_complexity = get_module_complexity(os.path.join('data', 'api'))\n",
    "frontend_mod_complexity = get_module_complexity(os.path.join('data', 'frontend'))\n",
    "\n",
    "def create_complexity_heatmap(complexity_data, title):\n",
    "    if not complexity_data:\n",
    "        print(f\"No complexity data available for {title}\")\n",
    "        return\n",
    "    df = pd.DataFrame(list(complexity_data.items()), columns=['Module', 'Complexity']).sort_values('Complexity', ascending=False)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.barh(df['Module'], df['Complexity'])\n",
    "    for i, bar in enumerate(bars):\n",
    "        comp = df['Complexity'].iloc[i]\n",
    "        if comp > 10:\n",
    "            bar.set_color('red')\n",
    "        elif comp > 5:\n",
    "            bar.set_color('orange')\n",
    "        else:\n",
    "            bar.set_color('green')\n",
    "    plt.xlabel('Average Cyclomatic Complexity')\n",
    "    plt.ylabel('Module')\n",
    "    plt.title(f\"{title} Module Complexity Heatmap\")\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    for i, v in enumerate(df['Complexity']):\n",
    "        plt.text(v + 0.1, i, f\"{v:.2f}\", va='center')\n",
    "    plt.savefig(f\"{title.lower()}_complexity_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "create_complexity_heatmap(api_mod_complexity, \"API\")\n",
    "create_complexity_heatmap(frontend_mod_complexity, \"Frontend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Module-Function Hierarchy View\n",
    "\n",
    "In this section, we create a hierarchical view that shows each module and its top five most complex functions. This view can help identify key functions in architecturally significant modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_complexity(directory):\n",
    "    result = subprocess.run([\"radon\", \"cc\", directory, \"-j\"], capture_output=True, text=True)\n",
    "    try:\n",
    "        data = json.loads(result.stdout)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error parsing JSON output from radon for {directory}\")\n",
    "        return {}\n",
    "    module_data = {}\n",
    "    for file_path, functions in data.items():\n",
    "        path_parts = Path(file_path).parts\n",
    "        module = path_parts[1] if len(path_parts) > 1 else Path(file_path).stem\n",
    "        if module.startswith('_'):\n",
    "            continue\n",
    "        if module not in module_data:\n",
    "            module_data[module] = []\n",
    "        for func in functions:\n",
    "            module_data[module].append({\n",
    "                'name': func['name'],\n",
    "                'complexity': func['complexity'],\n",
    "                'rank': func['rank']\n",
    "            })\n",
    "    return module_data\n",
    "\n",
    "api_detailed = get_detailed_complexity(os.path.join('data', 'api'))\n",
    "frontend_detailed = get_detailed_complexity(os.path.join('data', 'frontend'))\n",
    "\n",
    "def create_hierarchy_view(detailed_data, title):\n",
    "    if not detailed_data:\n",
    "        print(f\"No detailed complexity data available for {title}\")\n",
    "        return\n",
    "    G = nx.DiGraph()\n",
    "    G.add_node(title, type='root')\n",
    "\n",
    "    def get_color(comp):\n",
    "        if comp > 15:\n",
    "            return 'darkred'\n",
    "        elif comp > 10:\n",
    "            return 'red'\n",
    "        elif comp > 5:\n",
    "            return 'orange'\n",
    "        else:\n",
    "            return 'green'\n",
    "\n",
    "    for module, functions in detailed_data.items():\n",
    "        if functions:\n",
    "            avg_comp = sum(f['complexity'] for f in functions) / len(functions)\n",
    "            G.add_node(module, type='module', complexity=avg_comp, color=get_color(avg_comp))\n",
    "            G.add_edge(title, module)\n",
    "            top_funcs = sorted(functions, key=lambda x: x['complexity'], reverse=True)[:5]\n",
    "            for func in top_funcs:\n",
    "                node_name = f\"{module}.{func['name']}\"\n",
    "                G.add_node(node_name, type='function', complexity=func['complexity'], color=get_color(func['complexity']))\n",
    "                G.add_edge(module, node_name)\n",
    "\n",
    "    try:\n",
    "        pos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n",
    "    except Exception as e:\n",
    "        print(\"pygraphviz not available; falling back to spring layout\")\n",
    "        pos = nx.spring_layout(G, k=0.3, iterations=50)\n",
    "\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    root_nodes = [n for n, attr in G.nodes(data=True) if attr.get('type') == 'root']\n",
    "    module_nodes = [n for n, attr in G.nodes(data=True) if attr.get('type') == 'module']\n",
    "    function_nodes = [n for n, attr in G.nodes(data=True) if attr.get('type') == 'function']\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=root_nodes, node_size=1000, node_color='blue', alpha=0.8)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=module_nodes, node_size=500, \n",
    "                           node_color=[G.nodes[n]['color'] for n in module_nodes], alpha=0.8)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=function_nodes, node_size=300, \n",
    "                           node_color=[G.nodes[n]['color'] for n in function_nodes], alpha=0.8, node_shape='s')\n",
    "    nx.draw_networkx_edges(G, pos, arrows=True, arrowsize=15, alpha=0.6)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "    plt.title(f\"{title} Module-Function Hierarchy\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{title.lower()}_hierarchy.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "create_hierarchy_view(api_detailed, \"API\")\n",
    "create_hierarchy_view(frontend_detailed, \"Frontend\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
